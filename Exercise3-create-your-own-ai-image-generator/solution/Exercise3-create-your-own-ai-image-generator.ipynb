{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise: Create your own AI image generator\n",
        "\n",
        "In this exercise, you will create your own AI image generator. You will take the famous MNIST dataset and train a Variational Auto Encoder that will generate new images of handwritten digits.\n",
        "\n",
        "Here are the steps we will follow in this lesson:\n",
        "* Load the MNIST dataset\n",
        "* Create a Variational Auto Encoder\n",
        "* Train the Variational Auto Encoder\n",
        "* Generate new images\n",
        "\n",
        "\n",
        "Let's get started with setting up our environment."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First, we will ensure the dependencies for this notebook are installed and imported.\n",
        "\n",
        "# Dependencies for this notebook\n",
        "! pip install torch torchvision matplotlib > /dev/null\n",
        "\n",
        "# Imports for this notebook\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "    print('GPU is available!')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print('GPU is not available, CPU will be used.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load the MNIST dataset\n",
        "\n",
        "First, we will load the MNIST dataset. The MNIST dataset contains 60,000 training images of handwritten digits from zero to nine and 10,000 testing images. The images have been normalized and centered in a fixed size of 28 x 28 pixels. You can learn more about the dataset [here](https://huggingface.co/datasets/mnist)."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Next, we use HuggingFace's datasets library to load the MNIST dataset\n",
        "\n",
        "# Load the MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "# Create a PyTorch dataloader, which loads data in batches and shuffles the data so the order of the images\n",
        "# changes with each training epoch\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create a Variational Auto Encoder\n",
        "\n",
        "Next, we will create a Variational Auto Encoder. A Variational Auto Encoder is a type of neural network that can learn to generate new images. It is composed of two parts: an encoder and a decoder. Without going into the details too much, the encoder takes an image as input and outputs a vector of numbers that represents the image; whereas the decoder takes the vector of numbers as input and outputs an image. The encoder and decoder are trained together so that the decoder learns to generate images that look like the images in the training dataset."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Here, we define the architecture of our Variational Autoencoder (VAE)\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        # Encoder parts\n",
        "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
        "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
        "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
        "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
        "\n",
        "        # Decoder parts\n",
        "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
        "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
        "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        \n",
        "    def encoder(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
        "    \n",
        "    def sampling(self, mu, log_var):\n",
        "        std = torch.exp(0.5*log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps.mul(std).add_(mu) # return z sample\n",
        "        \n",
        "    def decoder(self, z):\n",
        "        h = F.relu(self.fc4(z))\n",
        "        h = F.relu(self.fc5(h))\n",
        "        return F.sigmoid(self.fc6(h)) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encoder(x.view(-1, 784))\n",
        "        z = self.sampling(mu, log_var)\n",
        "        return self.decoder(z), mu, log_var\n",
        "\n",
        "# Construct the model given these parameters\n",
        "vae = VAE(x_dim=784, h_dim1=512, h_dim2=256, z_dim=4)\n",
        "vae = vae.to(device) # move the model to the device (GPU or CPU)\n",
        "\n",
        "print(vae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 3: Train the Variational Auto Encoder\n",
        "\n",
        "Now that we have created our Variational Auto Encoder, we will train it on the MNIST dataset. We will train it for 6 epochs, which means that we will show the training dataset to the Variational Auto Encoder 6 times. We will also use a batch size of 128, which means that we will show 128 images to the Variational Auto Encoder at a time."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Here we define and optimizer and a loss function for our model\n",
        "\n",
        "# The Adam optimizer is a popular optimizer for deep learning models\n",
        "optimizer = optim.Adam(vae.parameters(), lr=5e-3)\n",
        "\n",
        "\n",
        "# The loss function for our VAE contains multiple parts. It's not important now to understand the details of\n",
        "# it, but it's good to know that this loss function is more complex than the other examples we will see.\n",
        "def loss_function(recon_x, x, mu, log_var):\n",
        "\n",
        "    # Reconstruction error. To measure how well we have reconstructed the input image.\n",
        "    # See https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss\n",
        "    reconstruction_error = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
        "\n",
        "    # KL divergence. In essence, this term ensures that the distribution predicted in the latent space\n",
        "    # is close to a standard normal distribution.\n",
        "    kl_divergence = -0.5 * torch.sum(log_var - log_var.exp() - mu.pow(2) + 1)\n",
        "\n",
        "    # Combining the two terms into a single loss value provides a trade-off between the two terms.\n",
        "    return reconstruction_error + kl_divergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Here we define a PyTorch training loop for our VAE for a single epoch\n",
        "\n",
        "def train_epoch(epoch, device=device):\n",
        "    vae.train() # set model to training mode\n",
        "    train_loss = 0\n",
        "\n",
        "    # iterate over the training data\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "\n",
        "        data = data.to(device) # move data to device\n",
        "        optimizer.zero_grad() # clear the gradients of all optimized variables\n",
        "        \n",
        "        output_images, mu, log_var = vae(data) # forward pass\n",
        "        loss = loss_function(output_images, data, mu, log_var) # calculate loss\n",
        "        \n",
        "        loss.backward() # backward pass\n",
        "        train_loss += loss.item() # update running training loss\n",
        "        optimizer.step() # perform a single optimization step (parameter update)\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Train Epoch: {epoch} '\n",
        "                  f'[{batch_idx * len(data)}/{len(train_loader.dataset)} {100. * batch_idx / len(train_loader):.0f}] '\n",
        "                  f'Loss: {loss.item() / len(data):.6f}'\n",
        "                  )\n",
        "    print(f'====> Epoch: {epoch} Average loss: {train_loss / len(train_loader.dataset):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Now let's train the model! With each epoch, we will see the loss decrease as the model learns to\n",
        "# reconstruct the input images.\n",
        "\n",
        "! rm -rf ./data/gen_mnist_img && mkdir -p ./data/gen_mnist_img\n",
        "\n",
        "z = torch.randn(16, vae.z_dim).to(device)\n",
        "\n",
        "def write_gen_mnist_img(z, vae, epoch):\n",
        "    with torch.no_grad():\n",
        "        z_decoded = vae.decoder(z).to(device)\n",
        "\n",
        "    filename = f'./data/gen_mnist_img/epoch_{epoch}.png'   \n",
        "    print(f\"Writing {filename}\")\n",
        "    save_image(z_decoded.view(16, 1, 28, 28), filename)\n",
        "\n",
        "for epoch in range(6):\n",
        "    if epoch % 3 == 0:\n",
        "        write_gen_mnist_img(z, vae, epoch)\n",
        "\n",
        "    train_epoch(epoch)\n",
        "\n",
        "write_gen_mnist_img(z, vae, epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# While training we generated images from the model. Let's take a look at them.\n",
        "\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "filenames = sorted(os.listdir('./data/gen_mnist_img'))\n",
        "\n",
        "for filename in filenames:\n",
        "    print(\"=========================================\")\n",
        "    print(filename)\n",
        "    display(Image('./data/gen_mnist_img/' + filename))\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice how before training the VAE, the images look like random noise. After training the VAE, the images look like handwritten digits."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 4: Generate new images\n",
        "\n",
        "Now that we have trained our Variational Auto Encoder, we can use it to generate new images. Our VAE uses a vector of 4 numbers to represent an image. We can generate a random vector of 4 numbers and use our VAE to generate an image from it. We can also interpolate between two vectors of 4 numbers and generate the images that lie between them."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's first generate 8 random handwritten digits\n",
        "\n",
        "# Generate 8 random handwritten digits\n",
        "z = torch.randn(8, vae.z_dim).to(device)\n",
        "\n",
        "# Decode the random digits\n",
        "with torch.no_grad():\n",
        "    z_decoded = vae.decoder(z).to(device)\n",
        "\n",
        "# Plot the decoded digits\n",
        "plt.figure(figsize=(8, 2))\n",
        "for i in range(8):\n",
        "    plt.subplot(1, 8, i+1)\n",
        "    plt.imshow(z_decoded[i].view(28, 28).cpu().numpy(), cmap='gray')\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's explore the space of z a little more. First, let's handcraft\n",
        "# vectors that should exhibit a smooth transition in the output space\n",
        "\n",
        "z = torch.tensor(\n",
        "    [\n",
        "        [ 0.0000,  0.0000,  0.0000,  -1.400],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -1.200],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -1.000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -0.800],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -0.600],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -0.400],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -0.200],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.2000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.4000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.6000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.8000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  1.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  1.2000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  1.4000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  1.6000],\n",
        "    ]\n",
        ") * 3\n",
        "\n",
        "# Then generate a handwritten digit from that vector.\n",
        "z_decoded = vae.decoder(z.to(device))\n",
        "\n",
        "filename = \"./data/smooth transtion 1.png\"\n",
        "save_image(z_decoded.view(16, 1, 28, 28), filename)\n",
        "display(Image(filename))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Congratulations! You have successfully created your own AI image generator."
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
