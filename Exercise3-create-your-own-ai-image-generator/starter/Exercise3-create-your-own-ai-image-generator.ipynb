{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise: Create your own AI image generator\n",
        "\n",
        "In this exercise, you will create your own AI image generator. You will take the famous MNIST dataset and train a Variational Auto Encoder that will generate new images of handwritten digits.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# https://download.pytorch.org/whl/torch_stable.html \n",
        "! pip install torch torchvision matplotlib > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# prerequisites\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# MNIST Dataset\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define a VAE\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        # encoder part\n",
        "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
        "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
        "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
        "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
        "        # decoder part\n",
        "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
        "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
        "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        \n",
        "    def encoder(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
        "    \n",
        "    def sampling(self, mu, log_var):\n",
        "        std = torch.exp(0.5*log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps.mul(std).add_(mu) # return z sample\n",
        "        \n",
        "    def decoder(self, z):\n",
        "        h = F.relu(self.fc4(z))\n",
        "        h = F.relu(self.fc5(h))\n",
        "        return F.sigmoid(self.fc6(h)) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encoder(x.view(-1, 784))\n",
        "        z = self.sampling(mu, log_var)\n",
        "        return self.decoder(z), mu, log_var\n",
        "\n",
        "# build model\n",
        "vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=4)\n",
        "\n",
        "# set device\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "vae"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "optimizer = optim.Adam(vae.parameters())\n",
        "# return reconstruction error + KL divergence losses\n",
        "def loss_function(recon_x, x, mu, log_var):\n",
        "    # Reconstruction error. To measure how well we have reconstructed the input image.\n",
        "    # See https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
        "\n",
        "    # KL divergence. To measure how closely the latent variables match a unit Gaussian distribution.\n",
        "    # See the original paper (\"Auto-Encoding Variational Bayes\")[https://arxiv.org/abs/1312.6114]\n",
        "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "\n",
        "    return BCE + KLD # total loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def train(epoch):\n",
        "    vae.train() # set model to training mode\n",
        "    train_loss = 0\n",
        "\n",
        "    # iterate over the training data\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "\n",
        "        data = data.to(device) # move data to device\n",
        "        optimizer.zero_grad() # clear the gradients of all optimized variables\n",
        "        \n",
        "        output_images, mu, log_var = vae(data) # forward pass\n",
        "        loss = loss_function(output_images, data, mu, log_var) # calculate loss\n",
        "        \n",
        "        loss.backward() # backward pass\n",
        "        train_loss += loss.item() # update running training loss\n",
        "        optimizer.step() # perform a single optimization step (parameter update)\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Train Epoch: {epoch} '\n",
        "                  f'[{batch_idx * len(data)}/{len(train_loader.dataset)} {100. * batch_idx / len(train_loader):.0f}] '\n",
        "                  f'Loss: {loss.item() / len(data):.6f}'\n",
        "                  )\n",
        "    print(f'====> Epoch: {epoch} Average loss: {train_loss / len(train_loader.dataset):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# def test():\n",
        "#     vae.eval()\n",
        "#     test_loss= 0\n",
        "#     with torch.no_grad():\n",
        "#         for data, _ in test_loader:\n",
        "#             # data = data.cuda()\n",
        "#             recon, mu, log_var = vae(data)\n",
        "            \n",
        "#             # sum up batch loss\n",
        "#             test_loss += loss_function(recon, data, mu, log_var).item()\n",
        "        \n",
        "#     test_loss /= len(test_loader.dataset)\n",
        "#     print('====> Test set loss: {:.4f}'.format(test_loss))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true
      },
      "source": [
        "! rm -rf gen_mnist_img && mkdir -p gen_mnist_img\n",
        "\n",
        "z = torch.randn(16, vae.z_dim).to(device)\n",
        "\n",
        "def write_gen_mnist_img(z, vae, epoch):\n",
        "    with torch.no_grad():\n",
        "        z_decoded = vae.decoder(z).to(device)\n",
        "\n",
        "    filename = f'./gen_mnist_img/epoch_{epoch}.png'   \n",
        "    print(f\"Writing {filename}\")\n",
        "    save_image(z_decoded.view(16, 1, 28, 28), filename)\n",
        "\n",
        "for epoch in range(6):\n",
        "    if epoch % 3 == 0:\n",
        "        write_gen_mnist_img(z, vae, epoch)\n",
        "\n",
        "    train(epoch)\n",
        "\n",
        "write_gen_mnist_img(z, vae, epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# for each image in the directory gen_mnist_img, show the image\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "filenames = sorted(os.listdir('./gen_mnist_img'))\n",
        "\n",
        "for filename in filenames:\n",
        "    print(\"=========================================\")\n",
        "    print(filename)\n",
        "    display(Image('./gen_mnist_img/' + filename))\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Each of the 16 digits is generated by a different 4 dimensional vector. Here\n",
        "# the variable z is a 16x4 matrix. Each row of z generates a single handwritten digit.\n",
        "z"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Let's explore the space of z a little more. First, let's handcraft\n",
        "# vectors that should exhibit a smooth transition in the output space\n",
        "\n",
        "z = torch.tensor(\n",
        "    [\n",
        "        [ 0.0000,  0.0000,  0.0000,  -1.400],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -1.200],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -1.000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -0.800],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -0.600],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -0.400],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -0.200],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.2000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.4000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.6000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.8000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  1.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  1.2000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  1.4000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  1.6000],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Then generate a handwritten digit from that vector.\n",
        "z_decoded = vae.decoder(z).to(device)\n",
        "\n",
        "filename = \"smooth transtion 1.png\"\n",
        "save_image(z_decoded.view(16, 1, 28, 28), filename)\n",
        "display(Image(filename))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Now try putting in your own numbers below. How many different digits can you \n",
        "# smoothly transition between?\n",
        "\n",
        "z = torch.tensor(\n",
        "    [\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Then generate a handwritten digit from that vector.\n",
        "z_decoded = vae.decoder(z).to(device)\n",
        "\n",
        "filename = \"smooth transtion 2.png\"\n",
        "save_image(z_decoded.view(16, 1, 28, 28), filename)\n",
        "display(Image(filename))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
