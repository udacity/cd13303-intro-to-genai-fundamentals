{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise: Create your own AI image generator\n",
        "\n",
        "In this exercise, you will create your own AI image generator. You will take the famous MNIST dataset and train a Variational Auto Encoder that will generate new images of handwritten digits.\n",
        "\n",
        "Let's get started!"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First, we will ensure the dependencies for this notebook are installed and imported.\n",
        "\n",
        "# Dependencies for this notebook\n",
        "! pip install torch torchvision matplotlib > /dev/null\n",
        "\n",
        "# Imports for this notebook\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the device\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "    print('GPU is available!')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print('GPU is not available, CPU will be used.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Next, we use HuggingFace's datasets library to load the MNIST dataset\n",
        "\n",
        "# Load the MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "# Create a PyTorch dataloader, which loads data in batches and shuffles the data so the order of the images\n",
        "# changes with each training epoch\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Here, we define the architecture of our Variational Autoencoder (VAE)\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        # Encoder parts\n",
        "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
        "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
        "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
        "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
        "\n",
        "        # Decoder parts\n",
        "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
        "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
        "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        \n",
        "    def encoder(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
        "    \n",
        "    def sampling(self, mu, log_var):\n",
        "        std = torch.exp(0.5*log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps.mul(std).add_(mu) # return z sample\n",
        "        \n",
        "    def decoder(self, z):\n",
        "        h = F.relu(self.fc4(z))\n",
        "        h = F.relu(self.fc5(h))\n",
        "        return F.sigmoid(self.fc6(h)) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encoder(x.view(-1, 784))\n",
        "        z = self.sampling(mu, log_var)\n",
        "        return self.decoder(z), mu, log_var\n",
        "\n",
        "# Construct the model given these parameters\n",
        "vae = VAE(x_dim=784, h_dim1=512, h_dim2=256, z_dim=4)\n",
        "vae = vae.to(device) # move the model to the device (GPU or CPU)\n",
        "\n",
        "print(vae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Here we define and optimizer and a loss function for our model\n",
        "\n",
        "# The Adam optimizer is a popular optimizer for deep learning models\n",
        "optimizer = optim.Adam(vae.parameters(), lr=5e-3)\n",
        "\n",
        "\n",
        "# The loss function for our VAE contains multiple parts. It's not important now to understand the details of\n",
        "# it, but it's good to know that this loss function is more complex than the other examples we will see.\n",
        "def loss_function(recon_x, x, mu, log_var):\n",
        "\n",
        "    # Reconstruction error. To measure how well we have reconstructed the input image.\n",
        "    # See https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss\n",
        "    reconstruction_error = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
        "\n",
        "    # KL divergence. In essence, this term ensures that the distribution predicted in the latent space\n",
        "    # is close to a standard normal distribution.\n",
        "    kl_divergence = -0.5 * torch.sum(log_var - log_var.exp() - mu.pow(2) + 1)\n",
        "\n",
        "    # Combining the two terms into a single loss value provides a trade-off between the two terms.\n",
        "    return reconstruction_error + kl_divergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Here we define a PyTorch training loop for our VAE for a single epoch\n",
        "\n",
        "def train_epoch(epoch, device=device):\n",
        "    vae.train() # set model to training mode\n",
        "    train_loss = 0\n",
        "\n",
        "    # iterate over the training data\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "\n",
        "        data = data.to(device) # move data to device\n",
        "        optimizer.zero_grad() # clear the gradients of all optimized variables\n",
        "        \n",
        "        output_images, mu, log_var = vae(data) # forward pass\n",
        "        loss = loss_function(output_images, data, mu, log_var) # calculate loss\n",
        "        \n",
        "        loss.backward() # backward pass\n",
        "        train_loss += loss.item() # update running training loss\n",
        "        optimizer.step() # perform a single optimization step (parameter update)\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Train Epoch: {epoch} '\n",
        "                  f'[{batch_idx * len(data)}/{len(train_loader.dataset)} {100. * batch_idx / len(train_loader):.0f}] '\n",
        "                  f'Loss: {loss.item() / len(data):.6f}'\n",
        "                  )\n",
        "    print(f'====> Epoch: {epoch} Average loss: {train_loss / len(train_loader.dataset):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Now let's train the model! With each epoch, we will see the loss decrease as the model learns to\n",
        "# reconstruct the input images.\n",
        "\n",
        "! rm -rf ./data/gen_mnist_img && mkdir -p ./data/gen_mnist_img\n",
        "\n",
        "z = torch.randn(16, vae.z_dim).to(device)\n",
        "\n",
        "def write_gen_mnist_img(z, vae, epoch):\n",
        "    with torch.no_grad():\n",
        "        z_decoded = vae.decoder(z).to(device)\n",
        "\n",
        "    filename = f'./data/gen_mnist_img/epoch_{epoch}.png'   \n",
        "    print(f\"Writing {filename}\")\n",
        "    save_image(z_decoded.view(16, 1, 28, 28), filename)\n",
        "\n",
        "for epoch in range(6):\n",
        "    if epoch % 3 == 0:\n",
        "        write_gen_mnist_img(z, vae, epoch)\n",
        "\n",
        "    train_epoch(epoch)\n",
        "\n",
        "write_gen_mnist_img(z, vae, epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for each image in the directory gen_mnist_img, show the image\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "filenames = sorted(os.listdir('./data/gen_mnist_img'))\n",
        "\n",
        "for filename in filenames:\n",
        "    print(\"=========================================\")\n",
        "    print(filename)\n",
        "    display(Image('./data/gen_mnist_img/' + filename))\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Each of the 16 digits is generated by a different 4 dimensional vector. Here\n",
        "# the variable z is a 16x4 matrix. Each row of z generates a single handwritten digit.\n",
        "z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's explore the space of z a little more. First, let's handcraft\n",
        "# vectors that should exhibit a smooth transition in the output space\n",
        "\n",
        "z = torch.tensor(\n",
        "    [\n",
        "        [ 0.0000,  0.0000,  0.0000,  -1.400],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -1.200],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -1.000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -0.800],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -0.600],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -0.400],\n",
        "        [ 0.0000,  0.0000,  0.0000,  -0.200],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.2000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.4000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.6000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.8000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  1.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  1.2000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  1.4000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  1.6000],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Then generate a handwritten digit from that vector.\n",
        "z_decoded = vae.decoder(z.to(device))\n",
        "\n",
        "filename = \"smooth transtion 1.png\"\n",
        "save_image(z_decoded.view(16, 1, 28, 28), filename)\n",
        "display(Image(filename))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now try putting in your own numbers below. How many different digits can you \n",
        "# smoothly transition between?\n",
        "\n",
        "z = torch.tensor(\n",
        "    [\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Then generate a handwritten digit from that vector.\n",
        "z_decoded = vae.decoder(z.to(device))\n",
        "\n",
        "filename = \"smooth transtion 2.png\"\n",
        "save_image(z_decoded.view(16, 1, 28, 28), filename)\n",
        "display(Image(filename))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
